---
title: "Tidyverse"
author: ''
date: ''
output:
  html_document:
    df_print: paged
subtitle: Guided practice
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(message = FALSE,warning = FALSE)
```

# Complex data wrangling with Tidyverse

## Importing the dataset: COVID-19 in USA

In this guided practice, we will see how to make complex data
transformations with tidyverse. We will work with the [COVID-19 cases in
USA
dataset](https://www.kaggle.com/datasets/sudalairajkumar/covid19-in-usa?select=us_counties_covid19_daily.csv)
at state level. First, let's read the dataframe.

```{r message=FALSE, warning=FALSE}
library(tidyverse)

data <- read_csv("./data/asec/us_states_covid19_daily.csv")

data
```

## Let's get Tidy

### select()

As we can see, it contains over 55 columns. Our first step will be to
select some variables, the ones we want to work with. In this case, we
have chosen date, state, positive, negative and probable cases, the test
source and number of results, and the cumulative information in
hospitals. We can do this with the function `select()`. We can simply
use it writing the name of the variables we want manually, but we can
also combine it with the renaming of variables and select variables that
match a pattern.

```{r}
data <- data %>% select(date, state, positive, 
                        probable_cases = probableCases, 
                        negative, 
                        contains("totalTests"))
```

Here, we renamed `probableCases` as `probable_cases` while we selected
it into our new dataframe. We also introduced the verb `contains()`,
which is a useful function to select variables that match a pattern. The
complete list of verbs available are:

-   `starts_with()`: Starts with an exact prefix.

-   `ends_with()`: Ends with an exact suffix.

-   `contains()`: Contains a literal string.

-   `matches()`: Matches a regular expression.

-   `num_range(x, 1:3)`: Matches a numerical range like x1, x2, x3.

These functions are what tidyverse calls [selection
helpers](https://tidyselect.r-lib.org/reference/language.html) for
variables. We will return to them in different examples of this
practice. For now, it is enough to know that these are a domain-specific
language for selecting specific variables.

### lubridate

Now, we want to transform the format of our variables. For example,
`date` is stored as a numeric variable:

```{r}
class(data$date)
```

We want to transform it to a date format. We will import `lubridate` in
order to do so:

```{r message=FALSE, warning=FALSE}
library(lubridate)
```

Now, we need to parse[^1] our date column with `lubridate` functions to
correct it. To generate date objects, we can call a function using `y`,
`m`, and `d` in the order in which the year (`y`), month (`m`), and date
(`d`) appear in our data.

[^1]: In parsing, **code is taken from the preprocessor, broken into
smaller pieces and analyzed so other software can understand it**.
The parser does this by building a data structure out of the pieces
of input.

```{r}
data <- data %>% mutate(date = ymd(date))

class(data$date)
```

This works for data in a numeric format, but also as strings!

```{r}
#Month-day-year 

mdy("March 28th, 2023")
```

We could also be interested in creating columns extracting year, month
and day in separate variables.

```{r}
data %>% 
  mutate(year = year(date),
         month = month(date),
         day = day(date)) %>%
  select(date, 
         year:day, 
         state:totalTestsAntigen)
```

We created three new columns. But since they were added, by default, to
the end of the dataframe, we also used the selection step to reorder the
variables. We used the selection helper `:` to get an interval of
columns. Writing `year:day` extracts all the columns year, day, and
every other one between them. It is the same as writing
`select(year, month, day)`, but saving up some lines of code. This is
specially useful for when we want to select a large number of variables,
like the ones between `state` and `totalTestResultsIncrease`.

### Quick quality check

We are interested in knowing the number of different types of tests each
state had. We have the information regarding the type of tests in the
columns that start with `totalTests`.

-   `totalTestsViral`: Total number of **PCR tests (or specimens
tested)** as reported by the state or territory.

-   `totalTestsPeopleViral`: Total number of **unique people tested at
least once via PCR testing**, as reported by the state or territory.

-   `totalTestsAntibody:` Total number of **completed antibody tests**
as reported by the state or territory.

-   `totalTestsPeopleAntibody:`The total number of **unique people who
have been tested at least once via antibody testing** as reported by
the state or territory.

-   `totalTestsAntigen:` Total number of **completed antigen tests**, as
reported by the state or territory.

-   `totalTestsPeopleAntigen:` Total number of **unique people who have
been tested at least once via antigen testing**, as reported by the
state or territory

According to this documentation, the total number of tests should
include the total number of people who were tested. However, some states
didn't register the information like so. Take for example Arizona:

```{r}
data %>% 
  filter(state == "AZ")
```

We see that they registered the number of total PCR tests in the column
of total people who were tested. So in order to get the complete number
of type of tests per state, without duplicating the values, we will make
a conditional replacement of the column.

We are going to make use of the **scoped** variant of `mutate`,
`mutate_at`, in order to change the values of multiple columns. Scoped
variants of tidyverse verbs apply an expression (sometimes several) to
all variables within a specified subset. This subset can contain:

-   all variables (`_all` variants)

-   a `vars()`, selection of multiple variables of different type (`_at`
variants)

-   or variables selected with a predicate (`_if` variants)

When we use `mutate_at`, we must call the variables in a vars()
argument, to indicate that we are selecting columns of the dataframe.
Next, we will combine this with the function `case_when()`.
`case_when()` allows us to vectorise multiple `if_else()` statements,
where each case is evaluated sequentially and the first match for each
element determines the corresponding value in the output vector.

```{r}
data <- data %>%
  mutate(totalTestsAntibody =  case_when(is.na(totalTestsAntibody) ~ totalTestsPeopleAntibody,
                                         TRUE ~ totalTestsAntibody),
         totalTestsViral = case_when(is.na(totalTestsViral) ~ totalTestsPeopleViral,
                                     TRUE ~ totalTestsViral),
         totalTestsAntigen = case_when(is.na(totalTestsAntigen) ~ totalTestsPeopleAntigen,
                                       TRUE ~ totalTestsAntigen))
```

## Reshaping and summarizing data

Now, we can use transformations to summarize and get aggregated
information from our data. For example,

In order to get this information, we need to reshape our tidy, wide data
into a long format. We will do this with the function `pivot_longer()`.

```{r}
test_data <- data %>%
  select(date, state, starts_with("totalTests")) %>%
  pivot_longer(cols = contains("totalTests"),
               names_prefix = 'totalTests',
               names_to = "type_test",
               values_to = "n") 

test_data
```

Since the data about tested people is now in the `totalTests` types of
variables, we can remove the rows that contain "totalTestsPeople" in
their name.

```{r}
test_data <- test_data %>% filter(!str_detect(type_test, "People"))
```

Before proceeding with the summary, we will rename our `type_test`
variables to more comprehensible names.

```{r}
test_data <- test_data %>% 
  mutate(type_test=case_when(
    type_test == "Viral" ~ "PCR",
    type_test == "Antibody" ~ "Antibody",
    type_test == "Antigen" ~ "Antigen"
  ))

test_data
```

Now we can group and count the number of tests per state. We will make
use of two functions:

-   `group_by()`: we will pass the names of the variables we want to use
as grouping criteria, in our case `state` and `type_test`.

-   `summarise()`: this is a function that is used to compute summary
statistics for a group of data. First, we need to set the name of
the output variable. We will use `total_n`. Then, we need to apply
the summary statistic we want to use. In our case, we want to get
the `sum()` of the values in `n` for each group. Since our dataset
has many NA values in the column we want to add, we will set the
parameter `na.rm = TRUE`, so these values are removed.

```{r}
grouped_data <- test_data %>%
  group_by(state, type_test) %>%
  summarise(total_n = sum(n, na.rm = TRUE))

grouped_data
```

## Merging data

Now, we will practice how to merge different dataframes, by looking into
the relationship between COVID-19 cases and deaths in counties and the
proportion of black population based on the [2017 US
Census](https://www.kaggle.com/datasets/muonneutrino/us-census-demographic-data).
First, we will read the two datasets:

```{r}
county_data <- read_csv('./data/asec/us_counties_covid19_daily.csv')

census_2017 <- read_csv('./data/asec/acs2017_county_data.csv')
```

`county_data` contains information regarding daily cases and deaths per
county in the US. First, we will get the total counts of both cases and
deaths in 2020, grouping the information.

```{r}
grouped_county <- county_data %>% 
  group_by(county, state, fips) %>%
  summarise(total_cases = sum(cases, na.rm = T),
            total_deaths = sum(deaths, na.rm = T))

grouped_county %>%
  arrange(-total_cases)
```

Take a look at the census data:

```{r}
census_2017
```

The variables we want to keep are: `CountyId` (which is the same as the
FIPS code seen in `county_data`), `TotalPop` and `Black`.

```{r}
census_subset <- census_2017 %>% select(CountyId, TotalPop, Black)
```

We can join the census data information with our COVID cases data, by
FIPS code. Since some of the counties in our dataset do not contain this
code, we will perform an `inner_join` in order to remove these cases. Of
course, for a serious analysis, it would be necessary to check which
counties are being ignored and what could be the consequences of this.

```{r}
joined_county <- grouped_county %>% 
  inner_join(census_subset, 
             by = c("fips" = "CountyId"))

joined_county
```

We want to look at the relationship between COVID cases and proportion
of black population in each county. We can't base this information on
absolute number of cases. Counties with a larger population will contain
a larger number of COVID cases, so we have to control this information
by county. Although the data is from 2017, it is still an useful way to
control the proportion of historically big and small counties.

```{r}
joined_county <- joined_county %>% 
  mutate(cases_pop = total_cases/TotalPop,
         deaths_pop = total_deaths/TotalPop) 

joined_county %>%
  arrange(-deaths_pop)
```

Just by looking at this print of information, it appears that counties
with a big proportion of black population had a bigger proportion of
COVID deaths per capita. Let's summarize this information to check:

```{r}
joined_county <- joined_county %>% 
  mutate(
    black_categorical = case_when(
      Black >= 50 ~ "Over 50% of the population is black",
      Black < 50 ~ "Under 50% of the population is black"
    ))


joined_county %>%
  group_by(black_categorical) %>%
  summarise(
    median_cases = median(cases_pop, na.rm = T),
    median_deaths = median(deaths_pop, na.rm = T)
  )
```

With this information, we can see that racial disparities can be shown
through Coronavirus data. These disparities were the result of
pre-pandemic realities, of a social and economic structure of domination
that has limited access to health and wealth for people of color.
