---
title: "Linear Regression"
subtitle: "Guided practice"
author: ""
date: ""
output: html_notebook
bibliography: references.bib
---

In this guided practice we will introduce R's workflow to build a simple linear regression model. We will first briefly explore a data set in order to choose our predictor and outcome variables, and afterwards fit a model and interpret our results.

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

```{r}
library(tidyverse)
options(scipen = 999)
```

The data set we will be using comprises a collection of indicators published by [Gapminder](https://www.gapminder.org/about/) for 123 countries in the year 2017.

```{r}
dataset <- readRDS("data/co2_econ/co2_income.RDS")

head(dataset,5)
#names(dataset)
```

```{r}
library(GGally)
```

The `ggpairs()` function of the *GGally* package is a powerful tool to create a matrix of plots describing the information within a given data set. For example, lets create this visualization for our data set:

```{r fig.height=8, message=FALSE}
#We will only keep numerical variables
gg_dataset <- dataset %>% select(-country)
#We will modify names in order to get tidyer labels
names(gg_dataset) <- gsub(x = names(gg_dataset), pattern = "\\_", replacement = " ") 

ggpairs(gg_dataset, labeller = label_wrap_gen(width=5))+
  theme_minimal()+
  theme(strip.text.x = element_text(size = 10),
           strip.text.y = element_text(size = 10))
```

# Building a linear regression model

We will be studying the relationship between per capita $CO_{2}$ emissions ($y$) and income ($X$). That is to say, we will try to estimate the parameters $\beta_{0}$ and $\beta_{1}$ of the model described by the following equation:

$$ y = \beta_{0} + \beta_{1}X + \epsilon$$

```{r}
#identifying outliers
plot_dataset <- dataset%>% 
  mutate(outlier = case_when(co2_emissions > 15.5 | income_ppp > 70000 ~ 1, TRUE ~ 0)) 

plot_dataset%>% 
  ggplot(.,aes(x = income_ppp, y = co2_emissions, alpha = as.character(outlier))) +
  geom_point(color = "springgreen4") + 
  scale_alpha_manual(values = c(1, 0.5))+
  geom_text(aes(label = country), data = subset(plot_dataset, outlier == 1), size = 2)+
  theme_minimal()+
  theme(legend.position = "none")
```

It seems like a positive linear relation might exist between both variables. However, a small group of countries present very high income levels and relatively low emission levels, or viceversa. Therefore, income is not the only relevant factor when trying to understand a country's carbon dioxide emission levels.

> ***Reflecting on the model assumptions**: Do the errors in this case follow the requirements of being normally distributed, with a mean equal to 0 and a constant variance?*

## Fitting our model

### Using tidymodels

```{r}
library(tidymodels)
```

When using tidymodels, specifying a model requires [@kuhnTidyModelingFramework2022]:

1.  Specifying the type of model (e.g., linear regression, random forest, KNN, etc).

2.  Specifying the engine for fitting the model.

3.  When required, declaring the mode of the model. The mode reflects the type of prediction outcome (for numeric outcomes, the mode is regression; this will always be the case for linear regression models).

```{r}
lm_spec <- linear_reg() %>%
  #set_mode("regression") %>%
  set_engine("lm")
```

Once the details of the model have been specified, the model estimation can be achieved using the fit() function: we must declare which data set to get our information from, the outcome variable -to the left of the \~ symbol-, and the predictor variable (or variables) -to its right-.

```{r}
lm_fit <- lm_spec %>%
  fit(co2_emissions ~ income_ppp, data = dataset)
```

This object will store our parameter's estimations. We can use the `tidy()` function to obtain information about our parameters:

```{r}
tidy(lm_fit) 
```

In this case, $\beta_{0} = 1.122$ and $\beta_{1} = 0.00015$.

$\beta_{0}$ represents the average value of $y$ when $X = 0$, that is to say, what the average emissions would be for a country with no income. In this case, there is no real life example of this situation. On the other hand, $\beta_{1}$ indicates the average increases in carbon emissions when income increases by one unit.

Note that the p-value corresponding to $\beta_{1}$ is almost equal to 0. We can therefore confidently reject the null hypothesis that states "no relationship exists between $X$ and $y$". That is, we consider the relationship between $X$ and $y$ to be statistically significant.

### Using a numerical approach

In order to obtain our coefficients using a numerical approach, we should first design an objective function to be minimized such as:

```{r}
squared_residuals <- function(params, data) {

  res_squared <- data %>% 
    rename("y" = co2_emissions, "x" = income_ppp) %>% 
    mutate(residual = y - (params[1] + params[2]*x)) %>% 
    mutate(res_2 = residual^2) %>% 
    pull(res_2)
  
  res <- sum(res_squared)
  
  return(res)
  
}
```

And afterwards we could just use the `optim()` function to extract our optimized parameter estimates choosing any random pair of initial parameter values (0 and 0).

```{r}
best <- optim(c(0, 0), squared_residuals, data = dataset)
```

The results in this case are also: $\beta_{0} = 1.122$ (`r round(best$par[1],3)`) and $\beta_{1} = 0.00015$ (`r round(best$par[2],5)`).

## Predictions and residuals

What emission values would our model predict for the countries in our data set knowing their income level?

$$ \hat{y_{i}} = \hat{\beta_{0}} + \hat{\beta_{1}}X $$

We could compute this predictions using:

```{r}
beta_0 <- tidy(lm_fit)$estimate[1]
beta_1 <- tidy(lm_fit)$estimate[2]

dataset %>% 
  select(co2_emissions, income_ppp) %>% 
  mutate(pred = beta_0 + income_ppp * beta_1)
```

We could therefore extract our residuals using:

```{r}
dataset %>% 
  select(co2_emissions, income_ppp) %>% 
  mutate(pred = beta_0 + income_ppp * beta_1) %>% 
  mutate(residuals = co2_emissions - pred)
```

The `augment()` function constitutes an easier way to append our predictions and their residuals to the data set.

```{r}
augment(lm_fit, new_data = dataset) %>% 
  select(co2_emissions, .pred, .resid)
```

Let's plot the residuals to check whether there are any issues with the model assumptions:

```{r}
plot_residuals <- augment(lm_fit, new_data = dataset) %>% 
  mutate(outlier = case_when(co2_emissions >15.5 | income_ppp > 70000 ~ 1, TRUE ~ 0)) 

plot_residuals%>% 
  ggplot(aes(x=.pred, y=.resid)) + 
  geom_point(alpha=.4) + 
  theme_minimal() +
  geom_hline(yintercept=0, linetype='dashed') +
  geom_text(aes(label = country), data = subset(plot_residuals, outlier == 1), size = 2)
```

When plotting our residuals, we can clearly observe that the countries we had initially identified as problematic are the ones with the largest residuals. That is to say, in this case our model fails to approximately predict the emissions level knowing their income.

## Evaluation

In order to quantify the proportion of variation in the emissions variable that can be explained by the linear model using the income variable, we can extract our model's coefficient of determination using:

```{r}
lm_fit %>% 
  pluck("fit") %>%
  summary()
```

In R's output, the coefficient of determination appears under the label "Multiple R-squared". In this case, it's value is of 0.472 in this case. That is to say, our model explains almost half the variability of our outcome variable.

# References
